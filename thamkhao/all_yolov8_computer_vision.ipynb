{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8640751,
          "sourceType": "datasetVersion",
          "datasetId": 5174843
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "TWt--t91C-8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS"
      ],
      "metadata": {
        "id": "r0kyYSrcToZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics opencv-python"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-08T15:17:06.035027Z",
          "iopub.execute_input": "2024-06-08T15:17:06.035393Z",
          "iopub.status.idle": "2024-06-08T15:17:18.401512Z",
          "shell.execute_reply.started": "2024-06-08T15:17:06.035357Z",
          "shell.execute_reply": "2024-06-08T15:17:18.400482Z"
        },
        "scrolled": true,
        "trusted": true,
        "id": "m1RrHgHdC-8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### detecttion (coco, open image v7)"
      ],
      "metadata": {
        "id": "IJGmcwZeZvXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\") # nano\n",
        "model = YOLO(\"yolov8s.pt\") # small\n",
        "model = YOLO(\"yolov8m.pt\") # medium\n",
        "model = YOLO(\"yolov8l.pt\") # large\n",
        "model = YOLO(\"yolov8x.pt\") # extra large\n",
        "\n",
        "data = \"coco.yaml\"\n",
        "\n",
        "# document\n",
        "# https://docs.ultralytics.com/tasks/detect/"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-08T15:20:03.083243Z",
          "iopub.execute_input": "2024-06-08T15:20:03.083612Z",
          "iopub.status.idle": "2024-06-08T15:20:15.201207Z",
          "shell.execute_reply.started": "2024-06-08T15:20:03.083581Z",
          "shell.execute_reply": "2024-06-08T15:20:15.200064Z"
        },
        "trusted": true,
        "id": "wygqX1hPC-8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### segmentation (coco)"
      ],
      "metadata": {
        "id": "c-S3GXmHau9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\") # nano\n",
        "model = YOLO(\"yolov8s-seg.pt\") # small\n",
        "model = YOLO(\"yolov8m-seg.pt\") # medium\n",
        "model = YOLO(\"yolov8l-seg.pt\") # large\n",
        "model = YOLO(\"yolov8x-seg.pt\") # extra large\n",
        "\n",
        "data = \"coco.yaml\"\n",
        "# or data = \"coco-seg.yaml\" --> lấy kết quả train từ coco.yaml :)) chứ cái data này bé tí\n",
        "\n",
        "# document\n",
        "# https://docs.ultralytics.com/tasks/segment/"
      ],
      "metadata": {
        "id": "yPr4srV1a0m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pose (coco)"
      ],
      "metadata": {
        "id": "xLHck51Tczm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n-pose.pt\") # nano\n",
        "model = YOLO(\"yolov8s-pose.pt\") # small\n",
        "model = YOLO(\"yolov8m-pose.pt\") # medium\n",
        "model = YOLO(\"yolov8l-pose.pt\") # large\n",
        "model = YOLO(\"yolov8x-pose.pt\") # extra large\n",
        "\n",
        "data = \"coco-pose.yaml\" # 1 class: person\n",
        "\n",
        "# document\n",
        "# https://docs.ultralytics.com/tasks/pose/"
      ],
      "metadata": {
        "id": "zjrrl3rtc4cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### obb (DOTAv1)"
      ],
      "metadata": {
        "id": "qMuLWyvdeeU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n-obb.pt\") # nano\n",
        "model = YOLO(\"yolov8s-obb.pt\") # small\n",
        "model = YOLO(\"yolov8m-obb.pt\") # medium\n",
        "model = YOLO(\"yolov8l-obb.pt\") # large\n",
        "model = YOLO(\"yolov8x-obb.pt\") # extra large\n",
        "\n",
        "# https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/DOTAv1.yaml\n",
        "data = \"DOTAv1.yaml\" # 15 class\n",
        "\n",
        "# document\n",
        "# https://docs.ultralytics.com/tasks/obb/"
      ],
      "metadata": {
        "id": "T7TEkk_3ekQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### classification (ImageNet)"
      ],
      "metadata": {
        "id": "lt4LPk3bg6Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n-cls.pt\") # nano\n",
        "model = YOLO(\"yolov8s-cls.pt\") # small\n",
        "model = YOLO(\"yolov8m-cls.pt\") # medium\n",
        "model = YOLO(\"yolov8l-cls.pt\") # large\n",
        "model = YOLO(\"yolov8x-cls.pt\") # extra large\n",
        "\n",
        "# https://docs.ultralytics.com/datasets/classify/imagenet/\n",
        "data = \"imagenet\"\n",
        "\n",
        "# document\n",
        "# https://docs.ultralytics.com/tasks/classify/"
      ],
      "metadata": {
        "id": "X1IKt-v5g48K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train model"
      ],
      "metadata": {
        "id": "KlR580h-sNV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Use the model\n",
        "model.train(data=\"coco8.yaml\", epochs=3)  # train model\n",
        "metrics = model.val()  # đánh giá hiệu suất mô hình trên tập xác thực"
      ],
      "metadata": {
        "id": "ilEj8gYLsQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONLY TRACKING - LINES"
      ],
      "metadata": {
        "id": "rrn1ptgLC-8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/kaggle/input/video-img-tracking/shop2.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define output video path\n",
        "output_video_path = \"output_video1.mp4\"\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "        results = model.track(frame, persist=True)\n",
        "\n",
        "        # Get the boxes and track IDs\n",
        "        boxes = results[0].boxes.xywh.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Plot the tracks\n",
        "        for box, track_id in zip(boxes, track_ids):\n",
        "            x, y, w, h = box\n",
        "            track = track_history[track_id]\n",
        "            track.append((float(x), float(y)))  # x, y center point\n",
        "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
        "                track.pop(0)\n",
        "\n",
        "            # Draw the tracking lines\n",
        "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(0, 255, 255), thickness=5)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        output_video.write(annotated_frame)\n",
        "\n",
        "#         # Break the loop if 'q' is pressed\n",
        "#         if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "#             break\n",
        "#     else:\n",
        "#         # Break the loop if the end of the video is reached\n",
        "#         break\n",
        "\n",
        "# Release the video capture object, release the VideoWriter object, and close the display window\n",
        "cap.release()\n",
        "output_video.release()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-06-08T15:34:42.726298Z",
          "iopub.execute_input": "2024-06-08T15:34:42.727103Z",
          "iopub.status.idle": "2024-06-08T15:36:18.44001Z",
          "shell.execute_reply.started": "2024-06-08T15:34:42.727068Z",
          "shell.execute_reply": "2024-06-08T15:36:18.438838Z"
        },
        "trusted": true,
        "id": "MKps2AdPC-8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRACKING - COUNTING - LINES"
      ],
      "metadata": {
        "id": "HqtUG65dC-8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/kaggle/input/video-img-tracking/Vehicles.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define output video path\n",
        "output_video_path = \"output_video11.mp4\"\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Initialize variables for counting vehicles\n",
        "vehicle_count = 0\n",
        "prev_frame_vehicles = set()\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "        results = model.track(frame, persist=True)\n",
        "\n",
        "        # Get the boxes and track IDs\n",
        "        boxes = results[0].boxes.xywh.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "        # Store current frame's vehicles\n",
        "        curr_frame_vehicles = set(track_ids)\n",
        "\n",
        "        # Count new vehicles\n",
        "        new_vehicles = curr_frame_vehicles - prev_frame_vehicles\n",
        "        vehicle_count += len(new_vehicles)\n",
        "\n",
        "        # Update previous frame's vehicles\n",
        "        prev_frame_vehicles = curr_frame_vehicles\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Plot the tracks\n",
        "        for box, track_id in zip(boxes, track_ids):\n",
        "            x, y, w, h = box\n",
        "            track = track_history[track_id]\n",
        "            track.append((float(x), float(y)))  # x, y center point\n",
        "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
        "                track.pop(0)\n",
        "\n",
        "            # Draw the tracking lines\n",
        "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(0, 255, 255), thickness=5)\n",
        "\n",
        "\n",
        "        # Draw a transparent black box for the text\n",
        "        box_coordinates = ((50, 20), (350, 80))  # Top-left and bottom-right coordinates\n",
        "        cv2.rectangle(annotated_frame, box_coordinates[0], box_coordinates[1], (0, 0, 0, 128), -1)  # Fill with black\n",
        "\n",
        "        # Write vehicle count on the frame\n",
        "        cv2.putText(annotated_frame, f\"Vehicle Count: {vehicle_count}\", (60, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 3)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        output_video.write(annotated_frame)\n",
        "\n",
        "#         # Break the loop if 'q' is pressed\n",
        "#         if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "#             break\n",
        "#     else:\n",
        "#         # Break the loop if the end of the video is reached\n",
        "#         break\n",
        "\n",
        "# Print the total number of vehicles\n",
        "print(\"Total vehicles detected:\", vehicle_count)\n",
        "\n",
        "# Release the video capture object, release the VideoWriter object, and close the display window\n",
        "cap.release()\n",
        "output_video.release()\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-06-08T15:46:56.312993Z",
          "iopub.execute_input": "2024-06-08T15:46:56.313777Z"
        },
        "trusted": true,
        "id": "_BlTFh1aC-8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HEATMAP (ORIGINAL)"
      ],
      "metadata": {
        "id": "id0GpgqbC-8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO, solutions\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Open video file\n",
        "cap = cv2.VideoCapture(\"/kaggle/input/video-img-tracking/tenis6.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Get video properties\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Initialize video writer\n",
        "video_writer = cv2.VideoWriter(\"heatmap_output1.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Initialize heatmap object\n",
        "heatmap_obj = solutions.Heatmap(\n",
        "    colormap=cv2.COLORMAP_PARULA,\n",
        "    view_img=True,\n",
        "    shape=\"circle\",\n",
        "    classes_names=model.names,\n",
        ")\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    # Perform tracking on the current frame\n",
        "    tracks = model.track(im0, persist=True, show=False)\n",
        "\n",
        "    # Generate heatmap on the frame\n",
        "    im0 = heatmap_obj.generate_heatmap(im0, tracks)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    video_writer.write(im0)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "video_writer.release()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-06-08T15:43:35.234616Z",
          "iopub.execute_input": "2024-06-08T15:43:35.235428Z",
          "iopub.status.idle": "2024-06-08T15:44:47.36503Z",
          "shell.execute_reply.started": "2024-06-08T15:43:35.235392Z",
          "shell.execute_reply": "2024-06-08T15:44:47.364081Z"
        },
        "trusted": true,
        "id": "z9HQdIBhC-8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HEATMAP (FROM DAT)"
      ],
      "metadata": {
        "id": "TVZeZLyoYYOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependences\n",
        "from ultralytics import YOLO, solutions\n",
        "from ultralytics.solutions import heatmap\n",
        "import imutils\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os  # Import thư viện os\n",
        "\n",
        "def track_createHeatmap(video_path, output_path, heatmap_output_path):\n",
        "    writer = None\n",
        "    (W, H) = (None, None)\n",
        "    weight_path = \"yolov8x.pt\"\n",
        "\n",
        "    # Kiểm tra sự tồn tại của tệp trọng số\n",
        "    if not os.path.exists(weight_path):\n",
        "        print(f\"Weight file not found: {weight_path}\")\n",
        "        return\n",
        "\n",
        "    model = YOLO(weight_path)\n",
        "\n",
        "    # read video\n",
        "    vs = cv.VideoCapture(video_path)\n",
        "    if not vs.isOpened():\n",
        "        print(f\"Failed to open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    classes_names = [\"person\"]\n",
        "    (grabbed, frame) = vs.read()\n",
        "    if not grabbed:\n",
        "        print(\"Failed to read video\")\n",
        "        return\n",
        "    h, w, c = frame.shape\n",
        "\n",
        "    # Init heatmap\n",
        "    heatmap_obj = heatmap.Heatmap(\n",
        "        colormap=cv.COLORMAP_PARULA,\n",
        "        imw=w,\n",
        "        imh=h,\n",
        "        view_img=False,  # Set to False for overall heatmap generation\n",
        "        view_in_counts=True,\n",
        "        shape=\"circle\",\n",
        "        decay_factor=1,  # No decay to keep the tracks visible\n",
        "        classes_names=model.names,\n",
        "    )\n",
        "\n",
        "    # Initialize the heatmap accumulator\n",
        "    heatmap_accumulator = np.zeros((h, w), dtype=np.float32)\n",
        "\n",
        "    while True:\n",
        "        # read the next frame from the file\n",
        "        (grabbed, frame) = vs.read()\n",
        "        if not grabbed:\n",
        "            break\n",
        "        tracks = model.track(frame, persist=True)\n",
        "        if not tracks:\n",
        "            continue  # Skip frames with no detections\n",
        "        for item in tracks:\n",
        "            if not item:  # Skip empty detections\n",
        "                continue\n",
        "            print(\"got it:-\", item[0].boxes)\n",
        "        try:\n",
        "            results = heatmap_obj.extract_results(tracks)\n",
        "        except AttributeError as e:\n",
        "            print(f\"Error extracting results: {e}\")\n",
        "            continue\n",
        "        print(\"result##:-\", results)\n",
        "        heatmap_frame = heatmap_obj.generate_heatmap(frame, tracks)\n",
        "\n",
        "        # Accumulate heatmap results\n",
        "        heatmap_accumulator += heatmap_obj.heatmap\n",
        "\n",
        "        if writer is None:\n",
        "            # initialize our video writer\n",
        "            fourcc = cv.VideoWriter_fourcc(*\"mp4v\")\n",
        "            writer = cv.VideoWriter(output_path, fourcc, 24,\n",
        "                                    (frame.shape[1], frame.shape[0]), True)\n",
        "        writer.write(heatmap_frame)\n",
        "\n",
        "    vs.release()\n",
        "    if writer is not None:\n",
        "        writer.release()\n",
        "\n",
        "    # Normalize the accumulated heatmap\n",
        "    heatmap_accumulator = cv.normalize(heatmap_accumulator, None, 0, 255, cv.NORM_MINMAX)\n",
        "    heatmap_accumulator = np.uint8(heatmap_accumulator)\n",
        "    heatmap_color = cv.applyColorMap(heatmap_accumulator, cv.COLORMAP_JET)\n",
        "\n",
        "    # Save the final heatmap image\n",
        "    cv.imwrite(heatmap_output_path, heatmap_color)\n",
        "\n",
        "# Gọi trực tiếp hàm track_createHeatmap với đường dẫn cụ thể của video\n",
        "video_path = \"/content/shop2.mp4\"\n",
        "output_path = \"shop2_heatmap1.mp4\"\n",
        "heatmap_output_path = \"shop2_heatmap1.png\"\n",
        "\n",
        "track_createHeatmap(video_path, output_path, heatmap_output_path)"
      ],
      "metadata": {
        "id": "kCQ276WFYTll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hmm"
      ],
      "metadata": {
        "id": "nM0zNZpOYjor"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8qWiJMvYUum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# đóng zip thư mục"
      ],
      "metadata": {
        "id": "Y0bk3-9sZSB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r outputs.zip /content/"
      ],
      "metadata": {
        "id": "e_hl5IMyZWSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}